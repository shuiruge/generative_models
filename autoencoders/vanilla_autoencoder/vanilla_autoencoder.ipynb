{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basic Idea of Machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a monkey drawing on a canvas (say, of `128 * 128` pixels). What's the probability that it draw a human-face? Almost none, isn't it. This implies that\n",
    "\n",
    "* the manifold of human-face involved in $\\mathbb{R}^{128 \\times 128}$ has relatively much smaller dimensions.\n",
    "\n",
    "* Even, the manifold is spares.\n",
    "\n",
    "To see this, imagine you modify the background of a painting with a human-face in the foreground, the points in $\\mathbb{R}^{128 \\times 128}$ before and after the modification are generally far from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the task of machine-learning is to find out the low-dimensional spares manifold, mapping the manifold to a lower dimensional compact space, and mapping the element there back to generate real-world object, like painting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the real-world object \"observable\", and the low-dimensional spares manifold \"latent\" space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This serves both to data-compression and data-abstraction. In fact, these are two aspects of one thing: the probability distribution of data (which we will talk in the next topic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic idea naturally forces to \"auto-encoder\", which has two parts:\n",
    "\n",
    "1. Encoder: mapping the observable to latent.\n",
    "2. Decoder: mapping the latent to observable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X$ the space of observable, and $Z$ the latent. Let $f: X \\mapsto Z$ denotes the encoder, and $g: Z \\mapsto X$ the decoder. Then, for $\\forall x \\in X$, we would expect\n",
    "\n",
    "\\begin{equation}\n",
    "  g \\circ f(x) \\approx x.\n",
    "\\end{equation}\n",
    "\n",
    "To numerically characterize this approximation, let $d_{\\text{obs}}$ some pre-defined distance in the space of observable, we can define loss\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathcal{L}_{\\text{recon}} = \\frac{1}{|D|} \\sum_{x \\in D} d_{\\text{obs}} \\left(x, g \\circ f (x) \\right).\n",
    "\\end{equation}\n",
    "\n",
    "We call this \"reconstruction\" loss, since $g \\circ f (x)$ is a reconstruction of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ensuring the compactness of the latent, an additional regularizer is added to the reconstruction loss, by some pre-defined distance in the latant space $d_{\\text{lat}}$. Thus, the total loss is\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathcal{L} = \\frac{1}{|D|} \\sum_{x \\in D} d_{\\text{obs}} \\left(x, g \\circ f (x) \\right)\n",
    "              + d_{\\text{lat}} \\left( f(x), 0 \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is thus to find the functions $f$ and $g$ that minimize the total loss. This utilizes the universality property of neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "  1. [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-e98df23d2c33>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dat/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dat/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../dat/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../dat/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../dat/MNIST/'\n",
    "mnist = input_data.read_data_sets(\n",
    "    data_path, one_hot=True,\n",
    "    source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(latent_dim, hidden_layers):\n",
    "    \n",
    "  def encoder(observable, name='encoder', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "      hidden = observable\n",
    "      for hidden_layer in hidden_layers:\n",
    "        hidden = tf.layers.dense(hidden, hidden_layer,\n",
    "                                 activation=tf.nn.relu)\n",
    "      latent = tf.layers.dense(hidden, latent_dim, activation=None)\n",
    "      return latent\n",
    "    \n",
    "  return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(observable_dim, hidden_layers):\n",
    "    \n",
    "  def decoder(latent, name='decoder', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "      hidden = latent\n",
    "      for hidden_layer in hidden_layers:\n",
    "        hidden = tf.layers.dense(hidden, hidden_layer,\n",
    "                                 activation=tf.nn.relu)\n",
    "      reconstructed = tf.layers.dense(hidden, observable_dim,\n",
    "                                      activation=tf.nn.sigmoid)\n",
    "      return reconstructed\n",
    "    \n",
    "  return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(observable, encoder, decoder, regularizer=None, reuse=None):\n",
    "  if regularizer is None:\n",
    "    regularizer = lambda latent: 0.0\n",
    "    \n",
    "  with tf.name_scope('loss'):\n",
    "    # shape: [batch_size, latent_dim]\n",
    "    latent = encoder(observable, reuse=reuse)\n",
    "    # shape: [batch_size, observable_dim]\n",
    "    reconstructed = decoder(latent, reuse=reuse)\n",
    "    # shape: [batch_size]\n",
    "    squared_errors = tf.reduce_sum(\n",
    "        (reconstructed - observable) ** 2,\n",
    "        axis=1)\n",
    "    mean_square_error = tf.reduce_mean(squared_errors)\n",
    "    return mean_square_error + regularizer(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "encoder = get_encoder(latent_dim=latent_dim,\n",
    "                      hidden_layers=[512, 256, 128])\n",
    "decoder = get_decoder(observable_dim=28*28,\n",
    "                      hidden_layers=[128, 256, 512])\n",
    "observable = tf.placeholder(shape=[None, 28*28],\n",
    "                            dtype='float32',\n",
    "                            name='observable')\n",
    "latent_samples = tf.placeholder(shape=[None, latent_dim],\n",
    "                                dtype='float32',\n",
    "                                name='latent_samples')\n",
    "generated = decoder(latent_samples, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(latent, name='regularizer'):\n",
    "  with tf.name_scope(name):\n",
    "    distances = tf.reduce_sum(latent ** 2, axis=1)\n",
    "    return tf.reduce_mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss = get_loss(observable, encoder, decoder,\n",
    "                regularizer=regularizer,\n",
    "                reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(epsilon=1e-3)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [03:53<00:00, 428.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 2.66785\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_vals = []\n",
    "for i in tqdm(range(100000)):\n",
    "  X, y = mnist.train.next_batch(batch_size=128)\n",
    "  _, loss_val = sess.run([train_op, loss], {observable: X})\n",
    "  loss_vals.append(loss_val)\n",
    "\n",
    "print('Final loss:', np.mean(loss_vals[-100:]))\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(array):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    array: Numpy array with shape `[28*28]`.\n",
    "    \n",
    "  Returns:\n",
    "    An image.\n",
    "  \"\"\"\n",
    "  array = 255 * array\n",
    "  array = array.reshape([28, 28])\n",
    "  array = array.astype(np.uint8)\n",
    "  return Image.fromarray(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAkUlEQVR4nMXQuw0CQQxF0Tu7IiWnApqgIEJCGiAgpRnqQKIDOgCJACFfAr6aHROCI8tH88Yy/Ln2OU0vwC7aGDrbaBtPGmGm4Qh10dYlrDX5FeAztqvxkL/LKq5fUI/1qLwMrBfoBr26Gqb29yjVUuH4kRGmFySclL4x72Gu59a2RIFq43cfAMfBOZ+6TeCndQMwUT5jZ/TpbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F5AF2EF2EB8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_sample_vals = np.random.normal(size=[1, latent_dim])\n",
    "generated_vals = sess.run(generated, {latent_samples: latent_sample_vals})\n",
    "get_image(generated_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
