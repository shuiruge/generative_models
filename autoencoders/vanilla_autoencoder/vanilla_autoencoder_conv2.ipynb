{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a re-implementation of the \"vanilla_autoencoder\" by CNN architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follows the blog: http://machinelearninguru.com/deep_learning/tensorflow/neural_networks/autoencoder/autoencoder.html\n",
    "(and its [github-page](https://github.com/Machinelearninguru/Deep_Learning/blob/master/TensorFlow/neural_networks/autoencoder/simple_autoencoder.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(observable, name='encoder', reuse=None):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    observable: Tensor of the shape `[batch_size, 32, 32, 1]`.\n",
    "      \n",
    "  Returns:\n",
    "    Tensor of the shape `[batch_size, 2, 2, 8]`.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(name, reuse=reuse):\n",
    "    # 32 x 32 x 1  ->  16 x 16 x 32\n",
    "    hidden = tf.layers.conv2d(observable, 32, [5, 5], strides=2, padding='SAME')\n",
    "    # 16 x 16 x 32  ->  8 x 8 x 16\n",
    "    hidden = tf.layers.conv2d(hidden, 16, [5, 5], strides=2, padding='SAME')\n",
    "    # 8 x 8 x 16  ->  2 x 2 x 8\n",
    "    latent = tf.layers.conv2d(hidden, 8, [5, 5], strides=4, padding='SAME')\n",
    "    return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(latent, name='decoder', reuse=None):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    latent: Tensor of the shape `[batch_size, 2, 2, 8]`.\n",
    "  \n",
    "  Returns:\n",
    "    Tensor of the shape `[batch_size, 32, 32, 1]`.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(name, reuse=reuse):\n",
    "    # 2 x 2 x 8  ->  8 x 8 x 16\n",
    "    hidden = tf.layers.conv2d_transpose(latent, 16, [5, 5], strides=4, padding='SAME')\n",
    "    # 8 x 8 x 16  ->  16 x 16 x 32\n",
    "    hidden = tf.layers.conv2d_transpose(hidden, 32, [5, 5], strides=2, padding='SAME')\n",
    "    # 16 x 16 x 32  ->  32 x 32 x 1\n",
    "    observable = tf.layers.conv2d_transpose(hidden, 1, [5, 5], strides=2, padding='SAME',\n",
    "                                            activation=tf.nn.tanh)\n",
    "    return observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_batch(images):\n",
    "    \"\"\"A function to resize a batch of MNIST images to (32, 32).\n",
    "    \n",
    "    Args:\n",
    "        images: Numpy array of the shape `[batch_size, 28 * 28]`.\n",
    "    Returns:\n",
    "        Numpy array of the shape `[batch_size, 32, 32]`.\n",
    "    \"\"\"\n",
    "    images = images.reshape((-1, 28, 28, 1))\n",
    "    resized_images = np.zeros((images.shape[0], 32, 32, 1))\n",
    "    for i in range(images.shape[0]):\n",
    "        resized_images[i, ..., 0] = transform.resize(images[i, ..., 0], (32, 32))\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(observable, encoder, decoder, regularizer=None, reuse=None):\n",
    "  if regularizer is None:\n",
    "    regularizer = lambda latent: 0.0\n",
    "    \n",
    "  with tf.name_scope('loss'):\n",
    "    # shape: [batch_size] + latent_dims\n",
    "    latent = encoder(observable, reuse=reuse)\n",
    "    # shape: [batch_size] + observable_dims\n",
    "    reconstructed = decoder(latent, reuse=reuse)\n",
    "    # shape: [batch_size]\n",
    "    squared_errors = tf.reduce_sum(\n",
    "        tf.layers.flatten((reconstructed - observable) ** 2),\n",
    "        axis=1)\n",
    "    mean_square_error = tf.reduce_mean(squared_errors)\n",
    "    return mean_square_error + regularizer(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "observable = tf.placeholder(shape=[None, 32, 32, 1],\n",
    "                            dtype='float32',\n",
    "                            name='observable')\n",
    "latent_samples = tf.placeholder(shape=[None, 2, 2, 8],\n",
    "                                dtype='float32',\n",
    "                                name='latent_samples')\n",
    "generated = decoder(latent_samples, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-86306f8048e8>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/shuiruge/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/shuiruge/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dat/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shuiruge/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dat/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shuiruge/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../dat/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../dat/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shuiruge/anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../dat/MNIST/'\n",
    "mnist = input_data.read_data_sets(\n",
    "    data_path, one_hot=True,\n",
    "    source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_batch(batch_size, mnist=mnist, source='train'):\n",
    "    \"\"\"Returns the X-batch as a numpy array of the shape\n",
    "    `[batch_size, 32, 32, 1]`.\"\"\"\n",
    "    if source == 'train':\n",
    "        dataset = mnist.train\n",
    "    elif source == 'test':\n",
    "        dataset = mnist.test\n",
    "    else:\n",
    "        raise ValueError('Argument `source` can either be \"train\" or '\n",
    "                         '\"test\". But now it is {}.'.format(source))\n",
    "        \n",
    "    X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "    X_batch = X_batch.reshape([-1, 28, 28, 1])\n",
    "    X_batch = resize_batch(X_batch)\n",
    "    return X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(latent, name='regularizer'):\n",
    "  with tf.name_scope(name):\n",
    "    latent = tf.layers.flatten(latent)\n",
    "    distances = tf.reduce_sum(latent ** 2, axis=1)\n",
    "    return tf.reduce_mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss(observable, encoder, decoder,\n",
    "                regularizer=regularizer,\n",
    "                reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(epsilon=1e-3)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 345/100000 [01:19<6:21:12,  4.36it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bc4ebc51af81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mobservable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mloss_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-007cff284eee>\u001b[0m in \u001b[0;36mget_X_batch\u001b[0;34m(batch_size, mnist, source)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-52a3cd5ca8e6>\u001b[0m in \u001b[0;36mresize_batch\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresized_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mresized_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresized_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shuiruge/anaconda/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    117\u001b[0m         out = warp(image, tform, output_shape=output_shape, order=order,\n\u001b[1;32m    118\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    preserve_range=preserve_range)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shuiruge/anaconda/lib/python3.6/site-packages/skimage/transform/_geometric.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_as_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shuiruge/anaconda/lib/python3.6/site-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36msafe_as_int\u001b[0;34m(val, atol)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         raise ValueError(\"Integer argument required but received \"\n",
      "\u001b[0;32m/Users/shuiruge/anaconda/lib/python3.6/site-packages/numpy/testing/nose_tools/utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[0;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1394\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Not equal to tolerance rtol=%g, atol=%g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[1;32m   1396\u001b[0m                          verbose=verbose, header=header, equal_nan=equal_nan)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "loss_vals = []\n",
    "for i in tqdm(range(100000)):\n",
    "  X_batch = get_X_batch(batch_size)\n",
    "  _, loss_val = sess.run([train_op, loss], {observable: X_batch})\n",
    "  if np.isnan(loss_Xy_val):\n",
    "    raise ValueError('Loss has been NaN.')\n",
    "  loss_vals.append(loss_val)\n",
    "\n",
    "print('Final loss:', np.mean(loss_vals[-100:]))\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(array):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    array: Numpy array with shape `[32, 32, 1]`.\n",
    "    \n",
    "  Returns:\n",
    "    An image.\n",
    "  \"\"\"\n",
    "  array = 255 * array\n",
    "  array = np.squeeze(array, axis=-1)\n",
    "  array = array.astype(np.uint8)\n",
    "  return Image.fromarray(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_sample_vals = np.random.normal(size=[128, 2, 2, 8])\n",
    "generated_vals = sess.run(generated, {latent_samples: latent_sample_vals})\n",
    "\n",
    "# Display the results\n",
    "n_display = 5\n",
    "for i in range(n_display):\n",
    "  print('Gnerated:')\n",
    "  display(get_image(generated_vals[i]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
