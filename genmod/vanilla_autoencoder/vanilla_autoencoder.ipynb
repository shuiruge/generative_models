{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basic Idea of Machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a monkey drawing on a canvas (say, of `128 * 128` pixels). What's the probability that it draw a human-face? Almost none, isn't it. This implies that\n",
    "\n",
    "* the manifold of human-face involved in $\\mathbb{R}^{128 \\times 128}$ has relatively much smaller dimensions.\n",
    "\n",
    "* Even, the manifold is spares.\n",
    "\n",
    "To see this, imagine you modify the background of a painting with a human-face in the foreground, the points in $\\mathbb{R}^{128 \\times 128}$ before and after the modification are generally far from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the task of machine-learning is to find out the low-dimensional spares manifold, mapping the manifold to a lower dimensional compact space, and mapping the element there back to generate real-world object, like painting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the real-world object \"observable\", and the low-dimensional spares manifold \"latent\" space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This serves both to data-compression and data-abstraction. In fact, these are two aspects of one thing: the probability distribution of data (which we will talk in the next topic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic idea naturally forces to \"auto-encoder\", which has two parts:\n",
    "\n",
    "1. Encoder: mapping the observable to latent.\n",
    "2. Decoder: mapping the latent to observable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X$ the space of observable, and $Z$ the latent. Let $f: X \\mapsto Z$ denotes the encoder, and $g: Z \\mapsto X$ the decoder. Then, for $\\forall x \\in X$, we would expect\n",
    "\n",
    "\\begin{equation}\n",
    "  g \\circ f(x) \\approx x.\n",
    "\\end{equation}\n",
    "\n",
    "To numerically characterize this approximation, let $d_{\\text{obs}}$ some pre-defined distance in the space of observable, we can define loss\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathcal{L}_{\\text{recon}} = \\frac{1}{|D|} \\sum_{x \\in D} d_{\\text{obs}} \\left(x, g \\circ f (x) \\right).\n",
    "\\end{equation}\n",
    "\n",
    "We call this \"reconstruction\" loss, since $g \\circ f (x)$ is a reconstruction of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ensuring the compactness of the latent, an additional regularizer is added to the reconstruction loss, by some pre-defined distance in the latant space $d_{\\text{lat}}$. Thus, the total loss is\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathcal{L} = \\frac{1}{|D|} \\sum_{x \\in D} d_{\\text{obs}} \\left(x, g \\circ f (x) \\right)\n",
    "              + d_{\\text{lat}} \\left( f(x), 0 \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is thus to find the functions $f$ and $g$ that minimize the total loss. This utilizes the universality property of neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "  1. [Wikipedia](https://en.wikipedia.org/wiki/Autoencoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-e98df23d2c33>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dat/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dat/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../dat/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../dat/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/apps/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../dat/MNIST/'\n",
    "mnist = input_data.read_data_sets(\n",
    "    data_path, one_hot=True,\n",
    "    source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(latent_dim, hidden_layers):\n",
    "    \n",
    "  def encoder(observable, name='encoder', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "      hidden = observable\n",
    "      for hidden_layer in hidden_layers:\n",
    "        hidden = tf.layers.dense(hidden, hidden_layer,\n",
    "                                 activation=tf.nn.relu)\n",
    "      latent = tf.layers.dense(hidden, latent_dim, activation=None)\n",
    "      return latent\n",
    "    \n",
    "  return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(observable_dim, hidden_layers):\n",
    "    \n",
    "  def decoder(latent, name='decoder', reuse=None):\n",
    "    with tf.variable_scope(name, reuse=reuse):\n",
    "      hidden = latent\n",
    "      for hidden_layer in hidden_layers:\n",
    "        hidden = tf.layers.dense(hidden, hidden_layer,\n",
    "                                 activation=tf.nn.relu)\n",
    "      reconstructed = tf.layers.dense(hidden, observable_dim,\n",
    "                                      activation=tf.nn.sigmoid)\n",
    "      return reconstructed\n",
    "    \n",
    "  return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(observable, encoder, decoder, regularizer=None, reuse=None):\n",
    "  if regularizer is None:\n",
    "    regularizer = lambda latent: 0.0\n",
    "    \n",
    "  with tf.name_scope('loss'):\n",
    "    # shape: [batch_size, latent_dim]\n",
    "    latent = encoder(observable, reuse=reuse)\n",
    "    # shape: [batch_size, observable_dim]\n",
    "    reconstructed = decoder(latent, reuse=reuse)\n",
    "    # shape: [batch_size]\n",
    "    squared_errors = tf.reduce_sum(\n",
    "        (reconstructed - observable) ** 2,\n",
    "        axis=1)\n",
    "    mean_square_error = tf.reduce_mean(squared_errors)\n",
    "    return mean_square_error + regularizer(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "encoder = get_encoder(latent_dim=latent_dim,\n",
    "                      hidden_layers=[512, 256, 128])\n",
    "decoder = get_decoder(observable_dim=28*28,\n",
    "                      hidden_layers=[128, 256, 512])\n",
    "observable = tf.placeholder(shape=[None, 28*28],\n",
    "                            dtype='float32',\n",
    "                            name='observable')\n",
    "latent_samples = tf.placeholder(shape=[None, latent_dim],\n",
    "                                dtype='float32',\n",
    "                                name='latent_samples')\n",
    "generated = decoder(latent_samples, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(latent, name='regularizer'):\n",
    "  with tf.name_scope(name):\n",
    "    distances = tf.reduce_sum(latent ** 2, axis=1)\n",
    "    return tf.reduce_mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss = get_loss(observable, encoder, decoder,\n",
    "                regularizer=regularizer,\n",
    "                reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(epsilon=1e-3)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [04:08<00:00, 402.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 2.68083\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_vals = []\n",
    "for i in tqdm(range(100000)):\n",
    "  X, y = mnist.train.next_batch(batch_size=128)\n",
    "  _, loss_val = sess.run([train_op, loss], {observable: X})\n",
    "  if np.isnan(loss_Xy_val):\n",
    "    raise ValueError('Loss has been NaN.')\n",
    "  loss_vals.append(loss_val)\n",
    "\n",
    "print('Final loss:', np.mean(loss_vals[-100:]))\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(array):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    array: Numpy array with shape `[28*28]`.\n",
    "    \n",
    "  Returns:\n",
    "    An image.\n",
    "  \"\"\"\n",
    "  array = 255 * array\n",
    "  array = array.reshape([28, 28])\n",
    "  array = array.astype(np.uint8)\n",
    "  return Image.fromarray(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gnerated:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnklEQVR4nNWPsRHCMAxFn+HgWIEx2IQFGIrBaDMHDQV3nB5FHKzgkB41svT1n2T4y9itiRpdbzNpUAIg0tAmDRYfACWOc8BZVU8Qalzq9JiiTJXghKt5myc/q+rDYkXAoR3R/gIUbNAsMnqTlsVRzY38z2vzL4Sqz2Vsx83Y+ze2c+Zrs7OLmShQbgNhvDpstGrWr1ZVYf9jz7B2RI43FTQ93giaJTYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD1C99E9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gnerated:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlUlEQVR4nMWQMQ7CMBAE10ZIFFR8Im9AlBSIV/MQRMUT0gQJbihASS4+u6FgG0t72vXcSX+XWWgnMwPgVs62jJrM/H3Pko4pXcPWtV6SJJcsBIeJoxjOvLyYuVUWSZzlk/foo7GnxUp8vQCnSPrWGdDqYR/cqBJMRlepZKdnBQmQrMa7MWXYV2mH5qIMJ0n9pbnwr3oDsbBHkF4DllUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD1C99E96D8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gnerated:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGNzg6////3DLOtLPISjgH3ZH3fv3/5/C6///0jGlxP/9w+6Tf//y////x2DYjizICKH+I3PggImBgYGBgQ1JBSbIxBts/HDWn/8BuJX9+/+fF7fsH1+swozr/qHYzILM+cvAiMvFDP/+/0vGJi74//////9xavv//yduN1IXAAD9ZDbJr0iVCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD1C99E9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gnerated:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAApklEQVR4nM2Ruw3CQBBE3xmLBImECsgI3As1ENGKQ0IqQBRCR2QG7ZDc2cftyUDGRKud2d8s/BlCmRCoiXGTE1dJtQLYmRJKyiTJNnRPSYtikiQD4OJLEwX3GtllTZIwbnvSNpO+nQAMZpLBCpMTLQkQZAdwlwA0e24Bk84p49ywMCXL2QB9CtqxYOzhrfWG/oj1cYZ8zHCmyqMj2sqjJ0jDx7W+wgtH71FakDWcPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD1C99E96D8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gnerated:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nNWRsRHCMAxFvwx3dDQ0dPQwAw2bMEqGYAG2YBPW4I6ORI/CsRMSOz2/sa0n60u29Kd6OJ8auzteQwCSpNvFJ0k7AA6Sk7Mki0s8EvpdHw0D21soOg61YlncmwxPCQaSJp4mCVLEsqdMkq9eEELMsLltKwlvZz054JLG75S7tzimnhQH2hSnHGu9BH/efGawXbpZ+9NrB1gRHR3gXa3ZcV5wnOgLDcRmDgVcDjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FD1C99E9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latent_sample_vals = np.random.normal(size=[128, latent_dim])\n",
    "generated_vals = sess.run(generated, {latent_samples: latent_sample_vals})\n",
    "\n",
    "# Display the results\n",
    "n_display = 5\n",
    "for i in range(n_display):\n",
    "  print('Gnerated:')\n",
    "  display(get_image(generated_vals[i]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
